#!/usr/bin/env node

import { readFile, writeFile, stat, readdir } from 'node:fs/promises'
import { join, extname } from 'node:path'
import { gzipSync } from 'node:zlib'

/**
 * æ„å»ºä¼˜åŒ–è„šæœ¬
 * ç”¨äºåˆ†æå’Œä¼˜åŒ–æ„å»ºäº§ç‰©ï¼Œå‡å°åº”ç”¨ä½“ç§¯
 */

const DIST_DIR = 'dist'
const TARGET_DIR = 'src-tauri/target/release'

/**
 * æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
 */
const formatSize = (bytes) => {
  const units = ['B', 'KB', 'MB', 'GB']
  let size = bytes
  let unitIndex = 0
  
  while (size >= 1024 && unitIndex < units.length - 1) {
    size /= 1024
    unitIndex++
  }
  
  return `${size.toFixed(2)} ${units[unitIndex]}`
}

/**
 * åˆ†ææ–‡ä»¶å¤§å°
 */
const analyzeFileSize = async (filePath) => {
  try {
    const stats = await stat(filePath)
    const content = await readFile(filePath)
    const gzipSize = gzipSync(content).length
    
    return {
      path: filePath,
      size: stats.size,
      gzipSize,
      compression: ((stats.size - gzipSize) / stats.size * 100).toFixed(1)
    }
  } catch (error) {
    return null
  }
}

/**
 * é€’å½’åˆ†æç›®å½•
 */
const analyzeDirectory = async (dirPath, results = []) => {
  try {
    const entries = await readdir(dirPath, { withFileTypes: true })
    
    for (const entry of entries) {
      const fullPath = join(dirPath, entry.name)
      
      if (entry.isDirectory()) {
        await analyzeDirectory(fullPath, results)
      } else {
        const analysis = await analyzeFileSize(fullPath)
        if (analysis) {
          results.push(analysis)
        }
      }
    }
  } catch (error) {
    console.warn(`âš ï¸ æ— æ³•åˆ†æç›®å½• ${dirPath}:`, error.message)
  }
  
  return results
}

/**
 * ç”Ÿæˆæ„å»ºæŠ¥å‘Š
 */
const generateBuildReport = async () => {
  console.log('ğŸ“Š å¼€å§‹åˆ†ææ„å»ºäº§ç‰©...')
  
  const frontendFiles = await analyzeDirectory(DIST_DIR)
  const backendFiles = await analyzeDirectory(TARGET_DIR)
  
  const allFiles = [...frontendFiles, ...backendFiles]
  
  // æŒ‰æ–‡ä»¶å¤§å°æ’åº
  allFiles.sort((a, b) => b.size - a.size)
  
  const totalSize = allFiles.reduce((sum, file) => sum + file.size, 0)
  const totalGzipSize = allFiles.reduce((sum, file) => sum + file.gzipSize, 0)
  
  const report = {
    timestamp: new Date().toISOString(),
    summary: {
      totalFiles: allFiles.length,
      totalSize: formatSize(totalSize),
      totalGzipSize: formatSize(totalGzipSize),
      compressionRatio: ((totalSize - totalGzipSize) / totalSize * 100).toFixed(1) + '%'
    },
    frontend: {
      files: frontendFiles.length,
      size: formatSize(frontendFiles.reduce((sum, f) => sum + f.size, 0)),
      gzipSize: formatSize(frontendFiles.reduce((sum, f) => sum + f.gzipSize, 0))
    },
    backend: {
      files: backendFiles.length,
      size: formatSize(backendFiles.reduce((sum, f) => sum + f.size, 0)),
      gzipSize: formatSize(backendFiles.reduce((sum, f) => sum + f.gzipSize, 0))
    },
    largestFiles: allFiles.slice(0, 10).map(file => ({
      path: file.path.replace(process.cwd() + '/', ''),
      size: formatSize(file.size),
      gzipSize: formatSize(file.gzipSize),
      compression: file.compression + '%'
    })),
    fileTypes: {}
  }
  
  // æŒ‰æ–‡ä»¶ç±»å‹åˆ†ç»„
  for (const file of allFiles) {
    const ext = extname(file.path) || 'no-extension'
    if (!report.fileTypes[ext]) {
      report.fileTypes[ext] = {
        count: 0,
        totalSize: 0,
        totalGzipSize: 0
      }
    }
    
    report.fileTypes[ext].count++
    report.fileTypes[ext].totalSize += file.size
    report.fileTypes[ext].totalGzipSize += file.gzipSize
  }
  
  // æ ¼å¼åŒ–æ–‡ä»¶ç±»å‹ç»Ÿè®¡
  for (const [ext, stats] of Object.entries(report.fileTypes)) {
    stats.totalSize = formatSize(stats.totalSize)
    stats.totalGzipSize = formatSize(stats.totalGzipSize)
  }
  
  return report
}

/**
 * è¾“å‡ºä¼˜åŒ–å»ºè®®
 */
const generateOptimizationSuggestions = (report) => {
  const suggestions = []
  
  // æ£€æŸ¥å¤§æ–‡ä»¶
  const largeFiles = report.largestFiles.filter(file => {
    const sizeInMB = parseFloat(file.size.split(' ')[0])
    return file.size.includes('MB') && sizeInMB > 1
  })
  
  if (largeFiles.length > 0) {
    suggestions.push({
      type: 'warning',
      title: 'å¤§æ–‡ä»¶æ£€æµ‹',
      description: `å‘ç° ${largeFiles.length} ä¸ªå¤§äº 1MB çš„æ–‡ä»¶ï¼Œå»ºè®®è¿›è¡Œä»£ç åˆ†å‰²æˆ–èµ„æºä¼˜åŒ–`,
      files: largeFiles.map(f => f.path)
    })
  }
  
  // æ£€æŸ¥å‹ç¼©ç‡
  const lowCompressionFiles = report.largestFiles.filter(file => {
    const compression = parseFloat(file.compression)
    return compression < 30
  })
  
  if (lowCompressionFiles.length > 0) {
    suggestions.push({
      type: 'info',
      title: 'å‹ç¼©ä¼˜åŒ–',
      description: 'ä»¥ä¸‹æ–‡ä»¶å‹ç¼©ç‡è¾ƒä½ï¼Œå¯èƒ½å·²ç»æ˜¯å‹ç¼©æ ¼å¼æˆ–å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–',
      files: lowCompressionFiles.map(f => f.path)
    })
  }
  
  // æ£€æŸ¥æ–‡ä»¶ç±»å‹åˆ†å¸ƒ
  const jsFiles = report.fileTypes['.js'] || { count: 0 }
  const cssFiles = report.fileTypes['.css'] || { count: 0 }
  
  if (jsFiles.count > 20) {
    suggestions.push({
      type: 'warning',
      title: 'JavaScript æ–‡ä»¶è¿‡å¤š',
      description: `å‘ç° ${jsFiles.count} ä¸ª JS æ–‡ä»¶ï¼Œå»ºè®®ä½¿ç”¨ä»£ç åˆ†å‰²å’Œæ‡’åŠ è½½ä¼˜åŒ–`
    })
  }
  
  if (cssFiles.count > 10) {
    suggestions.push({
      type: 'info',
      title: 'CSS æ–‡ä»¶ä¼˜åŒ–',
      description: `å‘ç° ${cssFiles.count} ä¸ª CSS æ–‡ä»¶ï¼Œå»ºè®®åˆå¹¶å’Œå‹ç¼©`
    })
  }
  
  return suggestions
}

/**
 * ä¸»å‡½æ•°
 */
const main = async () => {
  try {
    console.log('ğŸ”§ Kit æ„å»ºä¼˜åŒ–å™¨')
    console.log('==================')
    
    const report = await generateBuildReport()
    const suggestions = generateOptimizationSuggestions(report)
    
    // è¾“å‡ºæŠ¥å‘Š
    console.log('\nğŸ“Š æ„å»ºç»Ÿè®¡:')
    console.log(`æ€»æ–‡ä»¶æ•°: ${report.summary.totalFiles}`)
    console.log(`æ€»å¤§å°: ${report.summary.totalSize}`)
    console.log(`å‹ç¼©å: ${report.summary.totalGzipSize}`)
    console.log(`å‹ç¼©ç‡: ${report.summary.compressionRatio}`)
    
    console.log('\nğŸ¯ å‰ç«¯èµ„æº:')
    console.log(`æ–‡ä»¶æ•°: ${report.frontend.files}`)
    console.log(`å¤§å°: ${report.frontend.size}`)
    console.log(`å‹ç¼©å: ${report.frontend.gzipSize}`)
    
    console.log('\nâš™ï¸ åç«¯èµ„æº:')
    console.log(`æ–‡ä»¶æ•°: ${report.backend.files}`)
    console.log(`å¤§å°: ${report.backend.size}`)
    console.log(`å‹ç¼©å: ${report.backend.gzipSize}`)
    
    console.log('\nğŸ“ æœ€å¤§æ–‡ä»¶ (å‰10):')
    report.largestFiles.forEach((file, index) => {
      console.log(`${index + 1}. ${file.path} - ${file.size} (å‹ç¼©: ${file.gzipSize})`)
    })
    
    if (suggestions.length > 0) {
      console.log('\nğŸ’¡ ä¼˜åŒ–å»ºè®®:')
      suggestions.forEach((suggestion, index) => {
        const icon = suggestion.type === 'warning' ? 'âš ï¸' : 'â„¹ï¸'
        console.log(`${icon} ${suggestion.title}: ${suggestion.description}`)
        if (suggestion.files) {
          suggestion.files.forEach(file => console.log(`   - ${file}`))
        }
      })
    }
    
    // ä¿å­˜è¯¦ç»†æŠ¥å‘Š
    await writeFile('build-report.json', JSON.stringify(report, null, 2))
    console.log('\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ° build-report.json')
    
    console.log('\nâœ… æ„å»ºåˆ†æå®Œæˆ!')
    
  } catch (error) {
    console.error('âŒ æ„å»ºåˆ†æå¤±è´¥:', error)
    process.exit(1)
  }
}

// è¿è¡Œä¸»å‡½æ•°
if (import.meta.url === `file://${process.argv[1]}`) {
  main()
}

export { generateBuildReport, generateOptimizationSuggestions }